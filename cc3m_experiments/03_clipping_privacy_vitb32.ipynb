{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from rtpt.rtpt import setproctitle\n",
    "setproctitle('@Clipping_Privacy_CC3M_Notebook')\n",
    "os.chdir('/workspace')\n",
    "\n",
    "from datasets import FaceScrub, SingleClassSubset\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init clip\n",
    "RUN_PATHS = {\n",
    "    'top75': {'model_path': 'cc3m_experiments/checkpoints/vitb32_top75_epoch_50.pt'},\n",
    "    'top50': {'model_path': 'cc3m_experiments/checkpoints/vitb32_top50_epoch_50.pt'},\n",
    "    'top25': {'model_path': 'cc3m_experiments/checkpoints/vitb32_top25_epoch_50.pt'},\n",
    "    'top10': {'model_path': 'cc3m_experiments/checkpoints/vitb32_top10_epoch_50.pt'},\n",
    "    'top1': {'model_path': 'cc3m_experiments/checkpoints/vitb32_top01_epoch_50.pt'}\n",
    "}\n",
    "MODEL_NAME = 'ViT-B-32'\n",
    "DATASET_NAME = 'CC2M'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "models = {}\n",
    "for num_members in RUN_PATHS.keys():\n",
    "    # pretrained_model = wandb.restore(name=RUN_PATHS[num_members]['model_path'], run_path=RUN_PATHS[num_members]['run_path'])\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "        model_name=MODEL_NAME,\n",
    "        pretrained=RUN_PATHS[num_members]['model_path'],\n",
    "        precision='amp'\n",
    "    )\n",
    "    model = model.eval()\n",
    "    # only append the model since the preprocessing is the same for all the models since they are all the same model type\n",
    "    models[num_members] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the predictions for an actor/actress\n",
    "@torch.no_grad()\n",
    "def get_preds_for_dataset(model, subset, context, batch_size=8, num_workers=8, device=device):\n",
    "    datalaoder = DataLoader(subset, batch_size=batch_size, num_workers=num_workers, pin_memory=device == 'cuda')\n",
    "\n",
    "    preds = []\n",
    "    for x, _ in tqdm(datalaoder, desc='Iterating Dataset'):\n",
    "        x = x.to(device)\n",
    "        image_features, text_features, logits_scale = model(x, context)\n",
    "        # we have to calculate the cosine similarity manually. OpenAI does this internally.\n",
    "        logits_per_image = logits_scale  * image_features @ text_features.T\n",
    "        preds.append(logits_per_image.argmax(-1).cpu())\n",
    "\n",
    "    return torch.cat(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Member and the Non-Member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the non-members\n",
    "fs_actors_non_members = pd.read_csv(\n",
    "    'cc3m_experiments/conceptual_captions_facescrub_member_info/actors_non_members.csv', \n",
    "    index_col=0\n",
    ").rename(columns={'name': 'class_name'})\n",
    "fs_actors_non_members['name'] = fs_actors_non_members['class_name'].map(lambda x: x.replace('_', ' '))\n",
    "\n",
    "fs_actresses_non_members = pd.read_csv(\n",
    "    'cc3m_experiments/conceptual_captions_facescrub_member_info/actresses_non_members.csv', \n",
    "    index_col=0\n",
    ").rename(columns={'name': 'class_name'})\n",
    "fs_actresses_non_members['name'] = fs_actresses_non_members['class_name'].map(lambda x: x.replace('_', ' '))\n",
    "\n",
    "# load the members\n",
    "fs_actors_members = pd.read_csv(\n",
    "    'cc3m_experiments/conceptual_captions_facescrub_member_info/actors_members.csv', \n",
    "    index_col=0\n",
    ").rename(columns={'name': 'class_name'})\n",
    "fs_actors_members['name'] = fs_actors_members['class_name'].map(lambda x: x.replace('_', ' '))\n",
    "\n",
    "fs_actresses_members = pd.read_csv(\n",
    "    'cc3m_experiments/conceptual_captions_facescrub_member_info/actresses_members.csv', \n",
    "    index_col=0\n",
    ").rename(columns={'name': 'class_name'})\n",
    "fs_actresses_members['name'] = fs_actresses_members['class_name'].map(lambda x: x.replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_members = pd.concat([fs_actors_members, fs_actresses_members], ignore_index=True)\n",
    "cc_non_members = pd.concat([fs_actors_non_members, fs_actresses_non_members], ignore_index=True)\n",
    "cc_individuals = pd.concat([cc_members, cc_non_members], ignore_index=True)\n",
    "cc_individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load the FaceScrub Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facescrub = FaceScrub(root='./data/facescrub', group='all', train=True, cropped=False, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_subsets = []\n",
    "for class_idx in range(len(facescrub.classes)):\n",
    "    dataset_class_subsets.append(SingleClassSubset(facescrub, class_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize an example\n",
    "plt.imshow(dataset_class_subsets[facescrub.class_to_idx[cc_members['class_name'][0]]][2][0].permute(1,2,0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model for Test Purposes on the first Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the context vector of the possible labels\n",
    "split_class_names = [x.replace(\"_\", \" \") for x in facescrub.classes]\n",
    "label_context_vecs = open_clip.tokenize(split_class_names).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_dataset = dataset_class_subsets[facescrub.class_to_idx[cc_members['class_name'][0]]]\n",
    "for num_members, model in models.items():\n",
    "    model = model.to(device)\n",
    "    preds = get_preds_for_dataset(model, test_subset_dataset, label_context_vecs, num_workers=0)\n",
    "    unique_vals, counts = preds.unique(return_counts=True)\n",
    "    model = model.cpu()\n",
    "    prediction = unique_vals[counts.argmax()]\n",
    "    print(f'Prediction Model {num_members}: {facescrub.classes[prediction]}\\t Correct Class: {facescrub.classes[test_subset_dataset.target_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_dataset = dataset_class_subsets[facescrub.class_to_idx[cc_non_members['class_name'][0]]]\n",
    "for num_members, model in models.items():\n",
    "    model = model.to(device)\n",
    "    unique_vals, counts = get_preds_for_dataset(model, test_subset_dataset, label_context_vecs).unique(return_counts=True)\n",
    "    model = model.cpu()\n",
    "    prediction = unique_vals[counts.argmax()]\n",
    "    print(f'Prediction Model {num_members}: {facescrub.classes[prediction]}\\t Correct Class: {facescrub.classes[test_subset_dataset.target_class]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the CLIP model on all Actors\n",
    "Filter for (Non-)Members afterwards using Pands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dataset = ConcatDataset([subset for subset in dataset_class_subsets])\n",
    "preds_per_model = {}\n",
    "for num_members, model in models.items():\n",
    "    model = model.to(device)\n",
    "    preds = get_preds_for_dataset(model, concat_dataset, label_context_vecs, batch_size=256, num_workers=64)\n",
    "    model = model.cpu()\n",
    "    assert len(preds) == len(concat_dataset)\n",
    "    preds_per_model[num_members] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the large list of all predictions into prediction lists for every class\n",
    "preds_per_model_per_subset = {}\n",
    "for num_members, preds in preds_per_model.items():\n",
    "    preds_per_subset = []\n",
    "    counter = 0\n",
    "    for subset in dataset_class_subsets:\n",
    "        preds_per_subset.append(preds[counter:counter + len(subset)])\n",
    "        counter += len(subset)\n",
    "    preds_per_model_per_subset[num_members] = preds_per_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_per_model = {}\n",
    "for num_members in models.keys():\n",
    "    df_list = []\n",
    "    for group_idx, (dataset_subset, preds_subset) in enumerate(zip(dataset_class_subsets, preds_per_model_per_subset[num_members])):\n",
    "        for sample_idx, pred in enumerate(preds_subset):\n",
    "            class_name = facescrub.classes[dataset_class_subsets[group_idx].target_class]\n",
    "            df_list.append({\n",
    "                'group_idx': group_idx,\n",
    "                'class_name': class_name,\n",
    "                'sample_idx': sample_idx,\n",
    "                'prediction': facescrub.classes[int(pred)]\n",
    "            })\n",
    "    preds_df = pd.DataFrame(df_list)\n",
    "    preds_df_per_model[num_members] = preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the rows of the members and non-members\n",
    "for num_members, preds_df in preds_df_per_model.items():\n",
    "    members = pd.merge(preds_df, cc_members['class_name'], on='class_name')\n",
    "    members['actual_membership'] = 'member'\n",
    "    non_members = pd.merge(preds_df, cc_non_members['class_name'], on='class_name')\n",
    "    non_members['actual_membership'] = 'non_member'\n",
    "    preds_df_per_model[num_members] = pd.concat([members, non_members])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment this if you are running the notebook for the first time\n",
    "# for num_members, preds_df in preds_df_per_model.items():\n",
    "#     preds_df.to_csv(f'cc3m_experiments/prediction_dfs/predictions_{DATASET_NAME}_{MODEL_NAME}_{num_members}.csv')\n",
    "\n",
    "preds_df_per_model = {}\n",
    "for num_members, preds_df in models.items():\n",
    "    preds_df_per_model[num_members] = pd.read_csv(f'cc3m_experiments/prediction_dfs/predictions_{DATASET_NAME}_{MODEL_NAME}_{num_members}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_per_model['top75']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_sizes_per_model = {}\n",
    "for num_members, preds_df in preds_df_per_model.items():\n",
    "    min_num_images = preds_df.value_counts('class_name').sort_values()[0]\n",
    "    subsample_sizes = np.arange(0, min_num_images+1, 2).tolist()\n",
    "    subsample_sizes[0] = 1\n",
    "    subsample_sizes_per_model[num_members] = subsample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_dfs_per_model = {}\n",
    "sample_draws = 20\n",
    "for num_member_identities, preds_df in preds_df_per_model.items(): \n",
    "    subsample_sizes = subsample_sizes_per_model[num_member_identities]\n",
    "    subsampled_dfs = []\n",
    "    for sample_size in subsample_sizes:\n",
    "        for i in range(sample_draws):\n",
    "            membership_prediction_df = preds_df.groupby('class_name').sample(sample_size).groupby('class_name')['prediction'].agg(pd.Series.mode).apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else [x]).reset_index()\n",
    "            membership_prediction_df['membership_prediction'] = membership_prediction_df.apply(lambda x: 'member' if len(x['prediction']) == 1 and x['class_name'] in x['prediction'] else 'non_member', axis='columns')\n",
    "            membership_prediction_df = pd.merge(membership_prediction_df, preds_df[['class_name', 'actual_membership']].groupby('class_name')['actual_membership'].agg(pd.Series.mode), on='class_name')\n",
    "            num_member, num_non_member = membership_prediction_df['actual_membership'].value_counts()['member'], membership_prediction_df['actual_membership'].value_counts()['non_member']\n",
    "\n",
    "            tp = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'member') & (membership_prediction_df['actual_membership'] == 'member')])\n",
    "            fp = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'member') & (membership_prediction_df['actual_membership'] == 'non_member')])\n",
    "            fn = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'non_member') & (membership_prediction_df['actual_membership'] == 'member')])\n",
    "            tn = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'non_member') & (membership_prediction_df['actual_membership'] == 'non_member')])\n",
    "\n",
    "            subsampled_dfs.append({\n",
    "                'sample_size': sample_size,\n",
    "                'draw': i,\n",
    "                'tpr': tp / num_member,\n",
    "                'fnr': fn / num_member,\n",
    "                'fpr': fp / num_non_member,\n",
    "                'tnr': tn / num_non_member,\n",
    "                'tp': tp,\n",
    "                'fn': fn,\n",
    "                'fp': fp,\n",
    "                'tn': tn\n",
    "            })\n",
    "    subsampled_dfs_per_model[num_member_identities] = subsampled_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_members, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    subsampled_dfs_per_model[num_members] = pd.DataFrame(subsampled_dfs_per_model[num_members]).set_index('sample_size').drop('draw', axis='columns')\n",
    "    subsampled_dfs_per_model[num_members] = subsampled_dfs_per_model[num_members].rename(columns={'tpr': 'True Positive Rate', 'fnr': 'False Negative Rate', 'fpr': 'False Positive Rate', 'tnr': 'True Negative Rate'})\n",
    "    subsampled_dfs_per_model[num_members].index.name = 'Number of Samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_dfs_per_model['top75']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment this if you are running the notebook for the first time\n",
    "# for num_members, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "#     subsampled_dfs.to_csv(f'cc3m_experiments/prediction_dfs/sampled_predictions_{DATASET_NAME}_{MODEL_NAME}_{num_members}.csv')\n",
    "\n",
    "subsampled_dfs_per_model = {}\n",
    "for num_members, _ in models.items():\n",
    "    subsampled_dfs_per_model[num_members] = pd.read_csv(f'cc3m_experiments/prediction_dfs/sampled_predictions_{DATASET_NAME}_{MODEL_NAME}_{num_members}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_members, df in subsampled_dfs_per_model.items():\n",
    "    display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy for each sampling\n",
    "for num_members, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    subsampled_dfs_per_model[num_members]['Accuracy'] = (subsampled_dfs['tp'] + subsampled_dfs['tn']) / (subsampled_dfs['tp'] + subsampled_dfs['tn'] + subsampled_dfs['fp'] + subsampled_dfs['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "#for num_members, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "plt.clf()\n",
    "data = subsampled_dfs_per_model['top75'][['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate', 'Accuracy']]\n",
    "data = data.rename(columns={\n",
    "    'True Positive Rate': 'TPR', \n",
    "    'False Negative Rate': 'FNR', \n",
    "    'False Positive Rate': 'FPR', \n",
    "    'True Negative Rate': 'TNR', \n",
    "    'Accuracy': 'Acc'\n",
    "    }\n",
    ")\n",
    "ax = sns.lineplot(data=data, ci='sd')\n",
    "\n",
    "ax.set_xlabel(\"Number of Attack Samples\", weight=\"bold\", size=16)\n",
    "ax.set_xticklabels([int(x) for x in ax.get_xticks()], size=16)\n",
    "\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.set_yticklabels(ax.get_yticks(), size=16)\n",
    "ax.legend(h, l, ncol=2, loc='lower center', fontsize=16)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "plt.tight_layout()\n",
    "ax.get_figure().savefig(f'./cc3m_experiments/plots/subsample_plot_{DATASET_NAME}_{MODEL_NAME}_top75.pdf')\n",
    "ax.get_figure().savefig(f'./cc3m_experiments/plots/subsample_plot_{DATASET_NAME}_{MODEL_NAME}_top75.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_members, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    tp_std, fn_std, fp_std, tn_std = subsampled_dfs.groupby('Number of Samples').std().iloc[-1][['tp', 'fn', 'fp', 'tn']]\n",
    "    tp, fn, fp, tn = subsampled_dfs.groupby('Number of Samples').mean().iloc[-1][['tp', 'fn', 'fp', 'tn']]\n",
    "\n",
    "    tpr_std, fnr_std, fpr_std, tnr_std = subsampled_dfs.groupby('Number of Samples').std().iloc[-1][['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate']]\n",
    "    tpr, fnr, fpr, tnr = subsampled_dfs.groupby('Number of Samples').mean().iloc[-1][['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate']]\n",
    "\n",
    "    normalized_conf_mat = pd.DataFrame({'member': [tpr, fpr], 'non_member': [fnr, tnr]}, index=['member', 'non_member'])\n",
    "    normalized_conf_mat.index.set_names('Actual Membership', inplace=True)\n",
    "    normalized_conf_mat = normalized_conf_mat.rename_axis('Predicted Membership', axis='columns')\n",
    "\n",
    "    group_names = ['TP','FN','FP','TN']\n",
    "    group_counts = [\"{0:0.0f} \\u00B1 {1:0.2f}\".format(mean, std) for mean, std in zip([tp, fn, fp, tn], [tp_std, fn_std, fp_std, tn_std])]\n",
    "    percentage = [\"{0:0.2f}% \\u00B1 {1:0.02f}%\".format(mean * 100, std * 100) for mean, std in zip([tpr, fnr, fpr, tnr], [tpr_std, fnr_std, fpr_std, tnr_std])]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, percentage)]\n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(normalized_conf_mat, annot=np.asarray(labels).reshape(2, 2), fmt='', cbar=False, cmap='Blues')\n",
    "    plt.tight_layout()\n",
    "    ax.get_figure().savefig(f'./cc3m_experiments/plots/confusion_matrix_{DATASET_NAME}_RN50_{num_members}.pdf')\n",
    "    ax.get_figure().savefig(f'./cc3m_experiments/plots/confusion_matrix_{DATASET_NAME}_RN50_{num_members}.png', dpi=100)\n",
    "    print(num_members)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
