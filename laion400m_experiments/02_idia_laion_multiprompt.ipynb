{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset as PTConcatDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import os\n",
    "import bisect\n",
    "\n",
    "from rtpt.rtpt import setproctitle\n",
    "setproctitle('@Clipping_Privacy_LAION400M_Notebook')\n",
    "os.chdir('/workspace')\n",
    "\n",
    "from datasets import FaceScrub, SingleClassSubset\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init clip\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAMES = ['ViT-B-32', 'ViT-B-16', 'ViT-L-14']\n",
    "models = {}\n",
    "preprocessings = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained='laion400m_e32')\n",
    "    preprocessings[model_name] = preprocess\n",
    "    model = model.eval()\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Members and Non-Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laion_non_members = pd.read_csv('./laion400m_experiments/laion400m_non_members.csv', index_col=0).reset_index(drop=True).drop(['False', 'True'], axis='columns')\n",
    "\n",
    "laion_non_members['name'] = laion_non_members['class_name'].apply(lambda x: x.replace(\"_\", \" \"))\n",
    "print('Non-Members')\n",
    "display(laion_non_members)\n",
    "\n",
    "laion_members = pd.read_csv('./laion400m_experiments/laion400m_members.csv', index_col=0).reset_index(drop=True).drop(['False', 'True'], axis='columns')\n",
    "laion_members['name'] = laion_members['class_name'].apply(lambda x: x.replace(\"_\", \" \"))\n",
    "display(laion_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the FaceScrub Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(PTConcatDataset):\n",
    "    @property\n",
    "    def classes(self):\n",
    "        classes = []\n",
    "        for dataset in self.datasets:\n",
    "            classes.extend(dataset.classes)\n",
    "\n",
    "        return classes\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        targets = []\n",
    "        for i, dataset in enumerate(self.datasets):\n",
    "            max_target = sum([len(self.datasets[i].classes) for i in range(0, i)])\n",
    "            targets.extend((np.array(dataset.targets) + max_target).tolist())\n",
    "        \n",
    "        return targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0:\n",
    "            if -idx > len(self):\n",
    "                raise ValueError(\"absolute value of index should not exceed dataset length\")\n",
    "            idx = len(self) + idx\n",
    "        dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)\n",
    "        if dataset_idx == 0:\n",
    "            sample_idx = idx\n",
    "        else:\n",
    "            sample_idx = idx - self.cumulative_sizes[dataset_idx - 1]\n",
    "\n",
    "        x, y = self.datasets[dataset_idx][sample_idx]\n",
    "\n",
    "        max_target = sum([len(self.datasets[i].classes) for i in range(0, dataset_idx)])\n",
    "\n",
    "        return x, y + max_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facescrub_datasets = {model_name: FaceScrub(root='./data/facescrub', group='all', train=True, cropped=False, transform=preprocess) for model_name in MODEL_NAMES}\n",
    "laion_german_non_members_actors = {model_name: ImageFolder('./data/laion_german_non_members/actors/images', transform=preprocess) for model_name in MODEL_NAMES}\n",
    "laion_german_non_members_actresses = {model_name: ImageFolder('./data/laion_german_non_members/actresses/images', transform=preprocess) for model_name in MODEL_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_datasets = {model_name: ConcatDataset([facescrub_datasets[model_name], laion_german_non_members_actors[model_name], laion_german_non_members_actresses[model_name]]) for model_name in MODEL_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    print(f'---------- {model_name} ----------')\n",
    "    print(f'Dataset size: {len(concat_datasets[model_name])}')\n",
    "    print(f'First Few Classes: {concat_datasets[model_name].classes[:10]}')\n",
    "    print(f'Last Few Classes: {concat_datasets[model_name].classes[-10:]}')\n",
    "    print(f'Total Number of Classes: {len(concat_datasets[model_name].classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_subset_per_model = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    dataset_class_subsets = []\n",
    "    for class_idx in range(len(concat_datasets[model_name].classes)):\n",
    "        dataset_class_subsets.append(SingleClassSubset(concat_datasets[model_name], class_idx))\n",
    "    dataset_class_subset_per_model[model_name] = dataset_class_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first and last preprocessed image of the first class\n",
    "plt.imshow(dataset_class_subset_per_model[MODEL_NAMES[0]][0][0][0].permute(1,2,0).numpy())\n",
    "plt.show()\n",
    "plt.imshow(dataset_class_subset_per_model[MODEL_NAMES[0]][-1][0][0].permute(1,2,0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model for Test Purposes on the first Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the context vector of the possible labels\n",
    "split_class_names = {model_name: [x.replace(\"_\", \" \") for x in concat_datasets[model_name].classes] for model_name in MODEL_NAMES}\n",
    "label_context_vecs = {model_name: open_clip.tokenize(split_class_names[model_name]) for model_name in MODEL_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_class_names[MODEL_NAMES[0]][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the predictions for an actor/actress\n",
    "@torch.no_grad()\n",
    "def get_preds_for_dataset(model, subset, context, batch_size=8, num_workers=8, device=device):\n",
    "    datalaoder = DataLoader(subset, batch_size=batch_size, num_workers=num_workers, pin_memory=device == 'cuda')\n",
    "    \n",
    "    context = context.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    preds = []\n",
    "    for x, _ in tqdm(datalaoder, desc='Iterating Dataset'):\n",
    "        x = x.to(device)\n",
    "        image_features, text_features, logits_scale = model(x, context)\n",
    "        # we have to calculate the cosine similarity manually. OpenAI does this internally.\n",
    "        logits_per_image = logits_scale  * image_features @ text_features.T\n",
    "        preds.append(logits_per_image.argmax(-1).cpu())\n",
    "\n",
    "    model = model.cpu()\n",
    "    context = context.cpu()\n",
    "    return torch.cat(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_dataset = dataset_class_subset_per_model[MODEL_NAMES[0]][3]\n",
    "unique_vals, counts = get_preds_for_dataset(models[MODEL_NAMES[0]], test_subset_dataset, label_context_vecs[MODEL_NAMES[0]]).unique(return_counts=True)\n",
    "prediction = unique_vals[counts.argmax()]\n",
    "print(f'Prediction: {concat_datasets[MODEL_NAMES[0]].classes[prediction]}\\t Correct Class: {concat_datasets[MODEL_NAMES[0]].classes[test_subset_dataset.target_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_dataset = dataset_class_subset_per_model[MODEL_NAMES[0]][-3]\n",
    "unique_vals, counts = get_preds_for_dataset(models[MODEL_NAMES[0]], test_subset_dataset, label_context_vecs[MODEL_NAMES[0]]).unique(return_counts=True)\n",
    "prediction = unique_vals[counts.argmax()]\n",
    "print(f'Prediction: {concat_datasets[MODEL_NAMES[0]].classes[prediction]}\\t Correct Class: {concat_datasets[MODEL_NAMES[0]].classes[test_subset_dataset.target_class]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the CLIP model on each Actress/Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_per_model = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    dataset = PTConcatDataset(dataset_class_subset_per_model[model_name])\n",
    "    print(f'{model_name}:')\n",
    "    preds = get_preds_for_dataset(models[model_name], dataset, label_context_vecs[model_name], batch_size=256, num_workers=64)\n",
    "    assert len(preds) == len(dataset)\n",
    "    preds_per_model[model_name] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the large list of all predictions into prediction lists for every class\n",
    "preds_per_model_per_subset = {}\n",
    "for model_name, preds in preds_per_model.items():\n",
    "    preds_per_subset = []\n",
    "    counter = 0\n",
    "    for subset in dataset_class_subset_per_model[model_name]:\n",
    "        preds_per_subset.append(preds[counter:counter + len(subset)])\n",
    "        counter += len(subset)\n",
    "    preds_per_model_per_subset[model_name] = preds_per_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_per_model = {}\n",
    "for model_name in models.keys():\n",
    "    df_list = []\n",
    "    for group_idx, (dataset_subset, preds_subset) in enumerate(zip(dataset_class_subsets, preds_per_model_per_subset[model_name])):\n",
    "        for sample_idx, pred in enumerate(preds_subset):\n",
    "            class_name = concat_datasets[model_name].classes[dataset_class_subsets[group_idx].target_class]\n",
    "            df_list.append({\n",
    "                'group_idx': group_idx,\n",
    "                'class_name': class_name,\n",
    "                'sample_idx': sample_idx,\n",
    "                'prediction': concat_datasets[model_name].classes[int(pred)]\n",
    "            })\n",
    "    preds_df = pd.DataFrame(df_list)\n",
    "    preds_df_per_model[model_name] = preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_per_model[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the actual membership of the samples\n",
    "for model_name, preds_df in preds_df_per_model.items():\n",
    "    members = pd.merge(preds_df, laion_members['class_name'], on='class_name')\n",
    "    members['actual_membership'] = 'member'\n",
    "    non_members = pd.merge(preds_df, laion_non_members['class_name'], on='class_name')\n",
    "    non_members['actual_membership'] = 'non_member'\n",
    "    preds_df_per_model[model_name] = pd.concat([members, non_members]).reset_index(drop=True)\n",
    "\n",
    "preds_df_per_model[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_per_model['ViT-B-32'].groupby('class_name').sample(2).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_df_per_model[model_name].groupby('class_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_sizes_per_model = {}\n",
    "for model_name, preds_df in preds_df_per_model.items():\n",
    "    min_num_images = preds_df.value_counts('class_name').sort_values()[0]\n",
    "    subsample_sizes = np.arange(0, min_num_images+1, 2).tolist()\n",
    "    subsample_sizes[0] = 1\n",
    "    subsample_sizes_per_model[model_name] = subsample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_dfs_per_model = {}\n",
    "sample_draws = 20\n",
    "for model_name, preds_df in preds_df_per_model.items():\n",
    "    subsample_sizes = subsample_sizes_per_model[model_name]\n",
    "    subsampled_dfs = []\n",
    "    for sample_size in tqdm(subsample_sizes):\n",
    "        for i in range(sample_draws):\n",
    "            membership_prediction_df = preds_df.groupby('class_name').sample(sample_size).groupby('class_name')['prediction'].agg(pd.Series.mode).apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else [x]).reset_index()\n",
    "            membership_prediction_df['membership_prediction'] = membership_prediction_df.apply(lambda x: 'member' if len(x['prediction']) == 1 and x['class_name'] in x['prediction'] else 'non_member', axis='columns')\n",
    "            membership_prediction_df = pd.merge(membership_prediction_df, preds_df[['class_name', 'actual_membership']].groupby('class_name')['actual_membership'].agg(pd.Series.mode), on='class_name')\n",
    "            num_member, num_non_member = membership_prediction_df['actual_membership'].value_counts()['member'], membership_prediction_df['actual_membership'].value_counts()['non_member']\n",
    "\n",
    "            tp = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'member') & (membership_prediction_df['actual_membership'] == 'member')])\n",
    "            fp = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'member') & (membership_prediction_df['actual_membership'] == 'non_member')])\n",
    "            fn = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'non_member') & (membership_prediction_df['actual_membership'] == 'member')])\n",
    "            tn = len(membership_prediction_df[(membership_prediction_df['membership_prediction'] == 'non_member') & (membership_prediction_df['actual_membership'] == 'non_member')])\n",
    "\n",
    "            subsampled_dfs.append({\n",
    "                'sample_size': sample_size,\n",
    "                'draw': i,\n",
    "                'tpr': tp / num_member,\n",
    "                'fnr': fn / num_member,\n",
    "                'fpr': fp / num_non_member,\n",
    "                'tnr': tn / num_non_member,\n",
    "                'tp': tp,\n",
    "                'fn': fn,\n",
    "                'fp': fp,\n",
    "                'tn': tn\n",
    "            })\n",
    "    subsampled_dfs_per_model[model_name] = subsampled_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    subsampled_dfs_per_model[model_name] = pd.DataFrame(subsampled_dfs_per_model[model_name]).set_index('sample_size').drop('draw', axis='columns')\n",
    "    subsampled_dfs_per_model[model_name] = subsampled_dfs_per_model[model_name].rename(columns={'tpr': 'True Positive Rate', 'fnr': 'False Negative Rate', 'fpr': 'False Positive Rate', 'tnr': 'True Negative Rate'})\n",
    "    subsampled_dfs_per_model[model_name].index.name = 'Number of Samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_dfs_per_model['ViT-B-32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment this if you run the notebook for the first time to store the predictions to a file\n",
    "# for model_name, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "#     subsampled_dfs.to_csv(f'laion400m_experiments/prediction_dfs/predictions_laion_{model_name}.csv')\n",
    "subsampled_dfs_per_model = {}\n",
    "for model_name, _ in models.items():\n",
    "    subsampled_dfs_per_model[model_name] = pd.read_csv(f'laion400m_experiments/prediction_dfs/predictions_laion_{model_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_members, df in subsampled_dfs_per_model.items():\n",
    "    display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    plt.clf()\n",
    "    ax = sns.lineplot(data=subsampled_dfs[['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate']], ci='sd')\n",
    "    plt.tight_layout()\n",
    "    ax.get_figure().savefig(f'./laion400m_experiments/plots/subsample_plot_LAION400M_{model_name}.pdf')\n",
    "    ax.get_figure().savefig(f'./laion400m_experiments/plots/subsample_plot_LAION400M_{model_name}.png', dpi=100)\n",
    "    print(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, subsampled_dfs in subsampled_dfs_per_model.items():\n",
    "    tp_std, fn_std, fp_std, tn_std = subsampled_dfs.groupby('Number of Samples').std().iloc[-1][['tp', 'fn', 'fp', 'tn']]\n",
    "    tp, fn, fp, tn = subsampled_dfs.groupby('Number of Samples').mean().iloc[-1][['tp', 'fn', 'fp', 'tn']]\n",
    "\n",
    "    tpr_std, fnr_std, fpr_std, tnr_std = subsampled_dfs.groupby('Number of Samples').std().iloc[-1][['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate']]\n",
    "    tpr, fnr, fpr, tnr = subsampled_dfs.groupby('Number of Samples').mean().iloc[-1][['True Positive Rate', 'False Negative Rate', 'False Positive Rate', 'True Negative Rate']]\n",
    "\n",
    "    normalized_conf_mat = pd.DataFrame({'member': [tpr, fpr], 'non_member': [fnr, tnr]}, index=['member', 'non_member'])\n",
    "    normalized_conf_mat.index.set_names('Actual Membership', inplace=True)\n",
    "    normalized_conf_mat = normalized_conf_mat.rename_axis('Predicted Membership', axis='columns')\n",
    "\n",
    "    group_names = ['TP','FN','FP','TN']\n",
    "    group_counts = [\"{0:0.0f} \\u00B1 {1:0.2f}\".format(mean, std) for mean, std in zip([tp, fn, fp, tn], [tp_std, fn_std, fp_std, tn_std])]\n",
    "    percentage = [\"{0:0.2f}% \\u00B1 {1:0.02f}%\".format(mean * 100, std * 100) for mean, std in zip([tpr, fnr, fpr, tnr], [tpr_std, fnr_std, fpr_std, tnr_std])]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, percentage)]\n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(normalized_conf_mat, annot=np.asarray(labels).reshape(2, 2), fmt='', cbar=False, cmap='Blues')\n",
    "    plt.tight_layout()\n",
    "    ax.get_figure().savefig(f'./laion400m_experiments/plots/confusion_matrix_LAION400M_{model_name}.pdf')\n",
    "    ax.get_figure().savefig(f'./laion400m_experiments/plots/confusion_matrix_LAION400M_{model_name}.png', dpi=100)\n",
    "    print(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
