{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from IPython.display import display\n",
    "from clip_retrieval.clip_client import ClipClient, Modality\n",
    "from IPython.display import Image, display\n",
    "from base64 import b64decode\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import open_clip\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import itertools\n",
    "import wandb\n",
    "\n",
    "os.chdir('/workspace')\n",
    "from rtpt.rtpt import setproctitle\n",
    "setproctitle('@Clipping_Privacy_LAION400M_Notebook')\n",
    "\n",
    "from utils import TQDMParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if false, the results are loaded from the csv file\n",
    "QUERY_BACKEND = False\n",
    "CHECK_FACESCRUB_MEMBERSHIP = False\n",
    "CHECK_GERMAN_MEMBERSHIP = False\n",
    "NUM_IMAGES = 200\n",
    "MIN_IMAGES_PER_ACTOR_TO_USE_FOR_MEMBERS_AND_NON_MEMBERS = 30\n",
    "# to run this code you have to start multiple docker containers and run `clip_retrieval` for the LAION-400M dataset in each of the containers\n",
    "# after starting the docker containers get the ip addresses using the followinig command:\n",
    "# docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' <docker_container_name>\"\n",
    "CLIENT_URLS = [\n",
    "    'http://172.17.0.22:1337/knn-service',\n",
    "    'http://172.17.0.21:1337/knn-service',\n",
    "    'http://172.17.0.20:1337/knn-service',\n",
    "    'http://172.17.0.19:1337/knn-service',\n",
    "    'http://172.17.0.18:1337/knn-service',\n",
    "    'http://172.17.0.17:1337/knn-service',\n",
    "    'http://172.17.0.16:1337/knn-service',\n",
    "    'http://172.17.0.15:1337/knn-service',\n",
    "    'http://172.17.0.14:1337/knn-service',\n",
    "    'http://172.17.0.13:1337/knn-service',\n",
    "    'http://172.17.0.12:1337/knn-service',\n",
    "    'http://172.17.0.11:1337/knn-service',\n",
    "    'http://172.17.0.10:1337/knn-service',\n",
    "    'http://172.17.0.9:1337/knn-service',\n",
    "    'http://172.17.0.8:1337/knn-service',\n",
    "    'http://172.17.0.7:1337/knn-service',\n",
    "    'http://172.17.0.6:1337/knn-service',\n",
    "    'http://172.17.0.5:1337/knn-service',\n",
    "    'http://172.17.0.4:1337/knn-service',\n",
    "    'http://172.17.0.3:1337/knn-service'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for url in CLIENT_URLS:\n",
    "    clients.append(\n",
    "        ClipClient(\n",
    "            url=url,\n",
    "            indice_name='LAION-400M',\n",
    "            aesthetic_weight=0,\n",
    "            modality=Modality.IMAGE,\n",
    "            use_safety_model=False,\n",
    "            use_violence_detector=False,\n",
    "            deduplicate=False,\n",
    "            num_images=NUM_IMAGES\n",
    "        )\n",
    "    )\n",
    "len(clients)\n",
    "\n",
    "def log_result(result):\n",
    "    id, caption, url, similarity = result[\"id\"], result[\"caption\"], result[\"url\"], result[\"similarity\"]\n",
    "    print(f\"id: {id}\")\n",
    "    print(f\"caption: {caption}\")\n",
    "    print(f\"url: {url}\")\n",
    "    print(f\"similarity: {similarity}\")\n",
    "    display(Image(url=url, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Clip Retrieval to make sure it works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUERY_BACKEND:\n",
    "    for client in clients:\n",
    "        res = client.query(text='an image of a cat')\n",
    "        assert len(res) == NUM_IMAGES\n",
    "    cat = clients[-1].query(text='an image of a cat')\n",
    "    print(len(cat))\n",
    "    log_result(cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the FaceScrub Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_dataset = ImageFolder(root='./data/facescrub/actors/images')\n",
    "actresses_dataset = ImageFolder(root='./data/facescrub/actresses/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(actors_dataset[0][0])\n",
    "plt.show()\n",
    "plt.imshow(actresses_dataset[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the NUM_IMAGES most similar images to each of the images in the FaceScrub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_images(img, clip_retrieval_client):\n",
    "    res = []\n",
    "    try:\n",
    "        res = clip_retrieval_client.query(image=img)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "    \n",
    "    # if there was an internal server error just ignore the result\n",
    "    if len(res) == 1:\n",
    "        res = []\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUERY_BACKEND:\n",
    "    # get the similar images as list\n",
    "    sim_imgs_actors = TQDMParallel(n_jobs=len(clients), total=len(actors_dataset))(delayed(get_similar_images)(actors_dataset.imgs[i][0], clients[i%len(clients)]) for i in range(len(actors_dataset.imgs)))\n",
    "\n",
    "    # convert the list to a dictionary\n",
    "    actors_sim_imgs = {}\n",
    "    for i, (img, cls)in enumerate(actors_dataset.imgs):\n",
    "        actors_sim_imgs[img] = sim_imgs_actors[i]\n",
    "\n",
    "    # save the dictionary as a json file\n",
    "    with open(f'laion400m_experiments/face_scrub_top{NUM_IMAGES}_similar_laion400m_images_actors.json', 'w') as json_file:\n",
    "        json_file.write(json.dumps(actors_sim_imgs))\n",
    "elif CHECK_FACESCRUB_MEMBERSHIP:\n",
    "    with open(f'laion400m_experiments/face_scrub_top{NUM_IMAGES}_similar_laion400m_images_actors.json', 'r') as json_file:\n",
    "        actors_sim_imgs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUERY_BACKEND:\n",
    "    # do the same as above for the actresses\n",
    "    # get the similar images as list\n",
    "    sim_imgs_actresses = TQDMParallel(n_jobs=len(clients), total=len(actresses_dataset))(delayed(get_similar_images)(actresses_dataset.imgs[i][0], clients[i%len(clients)]) for i in range(len(actresses_dataset.imgs)))\n",
    "\n",
    "    # convert the list to a dictionary\n",
    "    actresses_sim_imgs = {}\n",
    "    for i, (img, cls)in enumerate(actresses_dataset.imgs):\n",
    "        actresses_sim_imgs[img] = sim_imgs_actresses[i]\n",
    "\n",
    "    # save the dictionary as a json file\n",
    "    with open(f'laion400m_experiments/face_scrub_top{NUM_IMAGES}_similar_laion400m_images_actresses.json', 'w') as json_file:\n",
    "        json_file.write(json.dumps(actresses_sim_imgs))\n",
    "elif CHECK_FACESCRUB_MEMBERSHIP:\n",
    "    with open(f'laion400m_experiments/face_scrub_top{NUM_IMAGES}_similar_laion400m_images_actresses.json', 'r') as json_file:\n",
    "        actresses_sim_imgs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(sim_imgs):\n",
    "    dataframes = []\n",
    "    for key in sim_imgs.keys():\n",
    "        df = pd.DataFrame(sim_imgs[key])\n",
    "        df['image'] = key\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    df = df[list(df.columns)[::-1]]\n",
    "    df['class_name'] = df.image.str.split('/').str[-1].str.split('.').str[:-1].str.join('.').str.split('_').str[:-1].str.join('_')\n",
    "\n",
    "    # fix the names of the actors and actresses\n",
    "    df.loc[df['class_name'] == 'Freddy_Prinze_Jr.', 'class_name'] = 'Freddie_Prinze_Jr'\n",
    "    df.loc[df['class_name'] == 'Leslie_Neilsen', 'class_name'] = 'Leslie_Nielsen'\n",
    "    df.loc[df['class_name'] == 'Robert_Di_Niro', 'class_name'] = 'Robert_De_Niro'\n",
    "    df.loc[df['class_name'] == 'Tatyana_M._Ali', 'class_name'] = 'Tatyana_Ali'\n",
    "    \n",
    "\n",
    "    df['name'] = df['class_name'].apply(lambda x: x.replace(\"_\", \" \"))\n",
    "    df['name_in_caption'] = df.apply(lambda x: x['name'] in x['caption'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "if CHECK_FACESCRUB_MEMBERSHIP:\n",
    "    actresses_df = create_df(actresses_sim_imgs)\n",
    "    actors_df = create_df(actors_sim_imgs)\n",
    "    df = pd.concat([actors_df, actresses_df], ignore_index=True)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_FACESCRUB_MEMBERSHIP:\n",
    "    num_images_per_actor = (df.groupby(['class_name']).size() / NUM_IMAGES).sort_values()\n",
    "    actors_with_num_images_above_threshold = num_images_per_actor[num_images_per_actor >= MIN_IMAGES_PER_ACTOR_TO_USE_FOR_MEMBERS_AND_NON_MEMBERS]\n",
    "    \n",
    "    grouped_caption_checks = df.groupby(['class_name', 'name_in_caption']).size().unstack(fill_value=0)\n",
    "\n",
    "    fs_non_members = grouped_caption_checks[grouped_caption_checks[True] == 0].reset_index()\n",
    "    fs_non_members = pd.merge(fs_non_members, actors_with_num_images_above_threshold.reset_index()['class_name'], on='class_name', how='inner').reset_index(drop=True)\n",
    "    fs_non_members.to_csv('./laion400m_experiments/laion400m_fs_non_members.csv')\n",
    "\n",
    "    fs_members = grouped_caption_checks[grouped_caption_checks[True] > 0].reset_index()\n",
    "    fs_members = pd.merge(fs_members, actors_with_num_images_above_threshold.reset_index()['class_name'], on='class_name', how='inner').reset_index(drop=True)\n",
    "    fs_members.to_csv('./laion400m_experiments/laion400m_fs_members.csv')\n",
    "else:\n",
    "    fs_non_members = pd.read_csv('./laion400m_experiments/laion400m_fs_non_members.csv', index_col=0)\n",
    "    fs_members = pd.read_csv('./laion400m_experiments/laion400m_fs_members.csv', index_col=0)\n",
    "print('Non-Members')\n",
    "display(fs_non_members)\n",
    "print('Members')\n",
    "display(fs_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Membership of the German Actors and Actresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_dataset = ImageFolder(root='./data/laion_german_non_members/actors/images')\n",
    "actresses_dataset = ImageFolder(root='./data/laion_german_non_members/actresses/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUERY_BACKEND:\n",
    "    # get the similar images as list\n",
    "    sim_imgs_actors = TQDMParallel(n_jobs=len(clients), total=len(actors_dataset))(delayed(get_similar_images)(actors_dataset.imgs[i][0], clients[i%len(clients)]) for i in range(len(actors_dataset.imgs)))\n",
    "\n",
    "    # convert the list to a dictionary\n",
    "    actors_sim_imgs = {}\n",
    "    for i, (img, cls)in enumerate(actors_dataset.imgs):\n",
    "        actors_sim_imgs[img] = sim_imgs_actors[i]\n",
    "\n",
    "    # save the dictionary as a json file\n",
    "    with open(f'laion400m_experiments/german_top{NUM_IMAGES}_similar_laion400m_images_actors.json', 'w') as json_file:\n",
    "        json_file.write(json.dumps(actors_sim_imgs))\n",
    "elif CHECK_GERMAN_MEMBERSHIP:\n",
    "    with open(f'laion400m_experiments/german_top{NUM_IMAGES}_similar_laion400m_images_actors.json', 'r') as json_file:\n",
    "        actors_sim_imgs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUERY_BACKEND:\n",
    "    # do the same as above for the actresses\n",
    "    # get the similar images as list\n",
    "    sim_imgs_actresses = TQDMParallel(n_jobs=len(clients), total=len(actresses_dataset))(delayed(get_similar_images)(actresses_dataset.imgs[i][0], clients[i%len(clients)]) for i in range(len(actresses_dataset.imgs)))\n",
    "\n",
    "    # convert the list to a dictionary\n",
    "    actresses_sim_imgs = {}\n",
    "    for i, (img, cls)in enumerate(actresses_dataset.imgs):\n",
    "        actresses_sim_imgs[img] = sim_imgs_actresses[i]\n",
    "\n",
    "    # save the dictionary as a json file\n",
    "    with open(f'laion400m_experiments/german_top{NUM_IMAGES}_similar_laion400m_images_actresses.json', 'w') as json_file:\n",
    "        json_file.write(json.dumps(actresses_sim_imgs))\n",
    "elif CHECK_GERMAN_MEMBERSHIP:\n",
    "    with open(f'laion400m_experiments/german_top{NUM_IMAGES}_similar_laion400m_images_actresses.json', 'r') as json_file:\n",
    "        actresses_sim_imgs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(sim_imgs):\n",
    "    dataframes = []\n",
    "    for key in sim_imgs.keys():\n",
    "        df = pd.DataFrame(sim_imgs[key])\n",
    "        df['image'] = key\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    df = df[list(df.columns)[::-1]]\n",
    "    df['class_name'] = df.image.str.split('/').str[-1].str.split('.').str[:-1].str.join('.').str.split('_').str[:-1].str.join('_')\n",
    "    df['name'] = df['class_name'].apply(lambda x: x.replace(\"_\", \" \"))\n",
    "    df['name_in_caption'] = df.apply(lambda x: x['name'] in x['caption'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "if CHECK_GERMAN_MEMBERSHIP:\n",
    "    actresses_df = create_df(actresses_sim_imgs)\n",
    "    actors_df = create_df(actors_sim_imgs)\n",
    "    df = pd.concat([actors_df, actresses_df], ignore_index=True)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_GERMAN_MEMBERSHIP:\n",
    "    num_images_per_actor = (df.groupby(['class_name']).size() / NUM_IMAGES).sort_values()\n",
    "    actors_with_num_images_above_threshold = num_images_per_actor[num_images_per_actor >= MIN_IMAGES_PER_ACTOR_TO_USE_FOR_MEMBERS_AND_NON_MEMBERS]\n",
    "\n",
    "    grouped_caption_checks = df.groupby(['class_name', 'name_in_caption']).size().unstack(fill_value=0)\n",
    "\n",
    "    german_non_members = grouped_caption_checks[grouped_caption_checks[True] == 0].reset_index()\n",
    "    german_non_members = pd.merge(german_non_members, actors_with_num_images_above_threshold.reset_index()['class_name'], on='class_name', how='inner').reset_index(drop=True)\n",
    "    german_non_members.to_csv('./laion400m_experiments/laion400m_german_non_members.csv')\n",
    "\n",
    "    german_members = grouped_caption_checks[grouped_caption_checks[True] > 0].reset_index()\n",
    "    german_members = pd.merge(german_members, actors_with_num_images_above_threshold.reset_index()['class_name'], on='class_name', how='inner').reset_index(drop=True)\n",
    "    german_members.to_csv('./laion400m_experiments/laion400m_german_members.csv')\n",
    "else:\n",
    "    german_non_members = pd.read_csv('./laion400m_experiments/laion400m_german_non_members.csv', index_col=0)\n",
    "    german_members = pd.read_csv('./laion400m_experiments/laion400m_german_members.csv', index_col=0)\n",
    "print('Non-Members')\n",
    "display(german_non_members)\n",
    "print('Members')\n",
    "display(german_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_members = pd.concat([fs_non_members, german_non_members]).reset_index(drop=True)\n",
    "non_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.concat([fs_members, german_members]).reset_index(drop=True)\n",
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_FACESCRUB_MEMBERSHIP and CHECK_GERMAN_MEMBERSHIP:\n",
    "    non_members.to_csv('./laion400m_experiments/laion400m_non_members.csv')\n",
    "else:\n",
    "    display(pd.read_csv('./laion400m_experiments/laion400m_non_members.csv', index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_FACESCRUB_MEMBERSHIP and CHECK_GERMAN_MEMBERSHIP:\n",
    "    members.to_csv('./laion400m_experiments/laion400m_members.csv')\n",
    "else:\n",
    "    display(pd.read_csv('./laion400m_experiments/laion400m_members.csv', index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
